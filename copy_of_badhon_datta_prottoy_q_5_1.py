# -*- coding: utf-8 -*-
"""Copy of BADHON DATTA.PROTTOY - Q_5_1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-_Q0fYzrhEg6cr-QgGXZKgWrldzcgY6m

# 5.1 Hierarchical Indexing & Pivot table

The objective of this problem is to analyse and prepare data from the "ydata_2.csv" file, which
contains transactions from Yahoo Buzz Game users during a specific period. The data
includes fields such as DATE, ANON_ID, MARKET_NAME, STOCK_NAME,
NUM_SHARES, AMOUNT, and PRICE_PER_SHARE. We will perform various data
processing tasks and prepare the data for a machine learning model.

Steps:
1. Data Reading and Formatting:

First we have to read the data from the "ydata_2.csv" file into a Pandas DataFrame.
The 'DATE' column should be converted to a datetime format, and only the date portion is to be retained for further analysis.

2. Aggregating Data by Date:

A new DataFrame named "df_datewise" is to be created by aggregating the data. It
calculates the total number of shares traded and the total transaction amount for each date. This information will be useful for tracking daily trading activities.

3. Identifying Unique Market Names:

Unique market names must be identified by extracting distinct values from the
'MARKET_NAME' column.

4. Identifying Unique Stock Names:

Similarly, unique stock names must be identified by extracting distinct values from the 'STOCK_NAME' column.

5. Mapping Markets to Associated Stocks:

Next step is to create a Pandas Series named "market_to_stocks" that clearly shows the mapping of markets to the stocks associated with each market. This mapping will provide insights into which stocks are traded in which markets.

6. Data Preparation for Machine Learning:

To prepare the data for a machine learning model, we need to create a pivot table. This table must have stocks as columns and date wise averages as values. The features include the daily average of the number of shares and the daily average of the price per share. If a stock is not listed on a specific date, the feature values must be filled with zeros. The resulting pivot table is structured to facilitate further analysis and machine learning tasks.

Ans to the question no 1
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

df = pd.read_csv('/content/drive/MyDrive/Badhon/ydata_2.csv')

print(df.columns)
df['DATE_TIME'] = pd.to_datetime(df['DATE_TIME']).dt.date

print(df.head())

"""Ans to the question no 2"""

df_datewise = df.groupby('DATE_TIME').agg({'NUM_SHARES': 'sum', 'AMOUNT': 'sum'}).reset_index()

print(df_datewise.head())

"""Ans to the question no 3"""

unique_market_names = df['MARKET_NAME'].unique()

print(unique_market_names)

"""Ans to the question no 4"""

unique_stock_names = df['STOCK_NAME'].unique()

print(unique_stock_names)

"""Ans to the question no 5"""

market_to_stocks = df.groupby('MARKET_NAME')['STOCK_NAME'].unique()

print(market_to_stocks)

"""Ans to the question no 6"""

pivot_table = df.pivot_table(index='DATE_TIME', columns='STOCK_NAME',
                             values=['NUM_SHARES', 'PRICE_PER_SHARE'],
                             aggfunc='mean', fill_value=0)

pivot_table.columns = [f'{col[0]}_{col[1]}' for col in pivot_table.columns]

pivot_table = pivot_table.reset_index()

print(pivot_table.head())