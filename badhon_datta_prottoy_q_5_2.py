# -*- coding: utf-8 -*-
"""BADHON DATTA.PROTTOY - Q_5_2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nhb0aR4FQDgz8HHS-lkc2a1zU5XOQ_X2

# 5.2 Data Preprocessing

The thyroid is a vital gland responsible for producing thyroid hormones, which play a crucial role in regulating various bodily functions such as breathing, body weight, heart rate, and muscle strength. Disorders related to the thyroid gland can have severe health implications. In this problem, we aim to prepare the data, ready to be fed to a machine learning model to predict whether a patient has a thyroid-related disorder based on various clinical features and tests.


1. Data Preparation

Step 1: Data Collection:
* The dataset used in this project must be obtained from the UCI Machine Learning Repository: https://archive.ics.uci.edu/dataset/102/thyroid+disease

Step 2: Reading Data:
* Read three files: "allhyper.data," "allhypo.data," and "sick.data," each containing different types of thyroid-related data.
* Column names must be same as that is provided in the dataset description.

Step 3: Data Exploration
* Verify the shapes of the three dataframes to ensure they are loaded correctly.
* Display the first five rows of each dataframe to get an initial understanding of the data.

Step 4: Handling Missing Data:
* Missing data is represented as "?" in the dataframes. Replace "?" with NaN values using the replace method.

Step 5: Identifying Missing Data:
* Count the number of NaN values in each column of the three dataframes.

Step 6: Data Cleaning:
* Columns containing NaN values alone (e.g., "TBG") and the "referral source" column must be dropped, as they are not relevant to our analysis.

Step 7: Category Preprocessing:
* Custom preprocessing on the "Category" column to extract relevant class information and to handle unwanted values must be performed.
* Apply method along with the preprocess_category function must be used to process the "Category" column for each dataframe.


Step 8: Data Stacking:
* After preprocessing, the three dataframes must be concatenated together creating a comprehensive dataset.

Step 9: Handling Duplicate Rows:
* Check for and remove duplicate rows in the concatenated dataframe using the
duplicated and drop_duplicates methods.

Step 10: Class Imbalance:
* Examine the distribution of classes in the "category" column to determine if there is any class imbalance.

Step 11: Removing Null Values:
* Rows with missing values in the "sex" and "age" columns must be removed from the dataset.

Step 12: Data Type Conversion and Imputation:
* Convert columns with missing data to "float" values to ensure compatibility.
* Impute missing values in the remaining columns with the median value using the
impute_nan_values function.

2. Model Training and Testing

Step 13: Splitting Data:
* Separate the dataset into features (X) and the target label (Y) in preparation for model training and testing.
* Perform a train-test split with a test size of 25% using train_test_split.

Step 14: Model Building:
* The next steps would involve feature engineering, model selection, and training. We can use various machine learning algorithms to build and evaluate models for thyroid disease classification.
"""

import pandas as pd

column_names = ["age", "sex", "on_thyroxine", "query_on_thyroxine", "on_antithyroid_medication",
                "sick", "pregnant", "thyroid_surgery", "I131_treatment", "query_hypothyroid",
                "query_hyperthyroid", "lithium", "goitre", "tumor", "hypopituitary", "psych",
                "TSH_measured", "TSH", "T3_measured", "T3", "TT4_measured", "TT4", "T4U_measured",
                "T4U", "FTI_measured", "FTI", "TBG_measured", "TBG", "referral_source", "Category"]

hyper_df = pd.read_csv('/content/drive/MyDrive/Badhon/allhyper.data', names=column_names, na_values="?")
hypo_df = pd.read_csv('/content/drive/MyDrive/Badhon/allhypo.data', names=column_names, na_values="?")
sick_df = pd.read_csv('/content/drive/MyDrive/Badhon/sick.data', names=column_names,na_values="?")

from google.colab import drive
drive.mount('/content/drive')

print(f'Hyperthyroid Data Shape: {hyper_df.shape}')
print(f'Hypothyroid Data Shape: {hypo_df.shape}')
print(f'Sick Data Shape: {sick_df.shape}')

print(hyper_df.head())
print(hypo_df.head())
print(sick_df.head())

print(hyper_df.isna().sum())
print(hypo_df.isna().sum())
print(sick_df.isna().sum())

columns_to_drop = ["TBG", "referral_source"]
hyper_df = hyper_df.drop(columns=columns_to_drop)
hypo_df = hypo_df.drop(columns=columns_to_drop)
sick_df = sick_df.drop(columns=columns_to_drop)

def preprocess_category(category):

    if 'hyperthyroid' in category.lower():
        return 'Hyperthyroid'
    elif 'hypothyroid' in category.lower():
        return 'Hypothyroid'
    elif 'sick' in category.lower():
        return 'Sick'
    else:
        return 'Healthy'

hyper_df['Category'] = hyper_df['Category'].apply(preprocess_category)
hypo_df['Category'] = hypo_df['Category'].apply(preprocess_category)
sick_df['Category'] = sick_df['Category'].apply(preprocess_category)

thyroid_df = pd.concat([hyper_df, hypo_df, sick_df], ignore_index=True)

thyroid_df = thyroid_df.drop_duplicates()

print(thyroid_df['Category'].value_counts())

thyroid_df = thyroid_df.dropna(subset=['sex', 'age'])

for col in thyroid_df.columns:
    if thyroid_df[col].dtype == 'object':
        continue
    thyroid_df[col] = thyroid_df[col].astype(float)
    thyroid_df[col].fillna(thyroid_df[col].median(), inplace=True)

from sklearn.model_selection import train_test_split

X = thyroid_df.drop(columns=['Category'])
Y = thyroid_df['Category']

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=42)